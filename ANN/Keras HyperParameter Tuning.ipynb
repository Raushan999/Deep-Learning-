{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec0742c",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138eb7c",
   "metadata": {},
   "source": [
    "### To decide the Number of Hidden Layers and the No of neurons in those layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5882e8f1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl (272.8 MB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading h5py-3.8.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 6.7 MB/s eta 0:00:00\n",
      "Collecting jax>=0.3.15 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached jax-0.4.12.tar.gz (1.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.1)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached grpcio-1.54.2-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting ml-dtypes>=0.1.0 (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl (938 kB)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_auth-2.19.1-py2.py3-none-any.whl (181 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.9/93.9 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.3/181.3 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.9)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.9/83.9 kB 4.9 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.12-py3-none-any.whl size=1498562 sha256=d41f3290025a1eeade149d6b15679b00ece358fb40adda8c89270e0943a9eca6\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\e8\\48\\6d\\8fc5366c9f000bd18db799e801d5e41c6a7f55d73fd3038b7e\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, oauthlib, ml-dtypes, markdown, keras, h5py, grpcio, google-pasta, gast, absl-py, rsa, requests-oauthlib, pyasn1-modules, jax, astunparse, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.19.1 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 h5py-3.8.0 jax-0.4.12 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 wheel-0.40.0 wrapt-1.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4446976f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_tuner\n",
      "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
      "     -------------------------------------- 176.1/176.1 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras_tuner) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras_tuner) (2.28.1)\n",
      "Collecting kt-legacy (from keras_tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->keras_tuner) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->keras_tuner) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->keras_tuner) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->keras_tuner) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->keras_tuner) (2022.6.15)\n",
      "Installing collected packages: kt-legacy, keras_tuner\n",
      "Successfully installed keras_tuner-1.3.5 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de963d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3c85103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Real_Combine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "546768c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T         0\n",
       "TM        0\n",
       "Tm        0\n",
       "SLP       0\n",
       "H         0\n",
       "VV        0\n",
       "V         0\n",
       "VM        0\n",
       "PM 2.5    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "# 1 null in PM 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ab72b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df['PM 2.5'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96e91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91feb8cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>PM 2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>219.720833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1018.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>182.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>154.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>20.6</td>\n",
       "      <td>223.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1017.3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>200.645833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T    TM   Tm     SLP     H   VV    V    VM      PM 2.5\n",
       "0   7.4   9.8  4.8  1017.6  93.0  0.5  4.3   9.4  219.720833\n",
       "1   7.8  12.7  4.4  1018.5  87.0  0.6  4.4  11.1  182.187500\n",
       "2   6.7  13.4  2.4  1019.4  82.0  0.6  4.8  11.1  154.037500\n",
       "3   8.6  15.5  3.3  1018.7  72.0  0.8  8.1  20.6  223.208333\n",
       "4  12.4  20.9  4.4  1017.3  61.0  1.3  8.7  22.2  200.645833"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a47c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating x and y features.\n",
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2347418",
   "metadata": {},
   "source": [
    "# Building custom function for the tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30692a",
   "metadata": {},
   "source": [
    "#### Hyperparameters below:\n",
    "1. How many hidden layers?\n",
    "2. How many neurons in each layer?\n",
    "3. Learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7190d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    # creating hidden layers (2 to 20 layers)\n",
    "    for i in range(hp.Int('num_layers',2,20)):\n",
    "        # no of neurons in each hidden layer.\n",
    "        model.add(layers.Dense(units=hp.Int('units_'+str(i),\n",
    "                                           min_value=32,\n",
    "                                           max_value=512,\n",
    "                                           step=32),\n",
    "                              activation='relu'))\n",
    "    # adding the output layer: linear for regression problems.\n",
    "    model.add(layers.Dense(1,activation='linear'))\n",
    "    # finally optimizing the model using Adam optimizer\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice(\n",
    "    'learning_rate',[1e-2,1e-3,1e-4])),\n",
    "                 loss='mean_absolute_error',\n",
    "                 metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa8cfe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from project1\\Air Quaility Index\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "build_model,\n",
    "objective='val_mean_absolute_error',\n",
    "max_trials=12,\n",
    "executions_per_trial=3,\n",
    "directory='project1',\n",
    "project_name='Air Quaility Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb1ba57b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 22\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_5 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_6 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_7 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_8 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_9 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_10 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_11 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_12 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_13 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_14 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_15 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_16 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_17 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_18 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_19 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf935876",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb35da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26d74fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c95b6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 00m 27s]\n",
      "val_mean_absolute_error: 61.29922231038412\n",
      "\n",
      "Best val_mean_absolute_error So Far: 44.214717864990234\n",
      "Total elapsed time: 00h 04m 47s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# tuner is random search object\n",
    "tuner.search(x_train,y_train,epochs=15,\n",
    "            validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25f06d98",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in project1\\Air Quaility Index\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_mean_absolute_error\", direction=\"min\")\n",
      "\n",
      "Trial 10 summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 320\n",
      "units_1: 352\n",
      "learning_rate: 0.01\n",
      "units_2: 64\n",
      "units_3: 32\n",
      "units_4: 32\n",
      "units_5: 256\n",
      "units_6: 320\n",
      "units_7: 256\n",
      "units_8: 512\n",
      "units_9: 320\n",
      "units_10: 64\n",
      "units_11: 320\n",
      "units_12: 32\n",
      "units_13: 32\n",
      "units_14: 384\n",
      "units_15: 256\n",
      "units_16: 448\n",
      "units_17: 160\n",
      "units_18: 416\n",
      "units_19: 480\n",
      "Score: 44.214717864990234\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 96\n",
      "units_1: 32\n",
      "learning_rate: 0.01\n",
      "units_2: 256\n",
      "units_3: 256\n",
      "units_4: 416\n",
      "units_5: 416\n",
      "units_6: 480\n",
      "units_7: 160\n",
      "units_8: 128\n",
      "units_9: 416\n",
      "units_10: 32\n",
      "units_11: 64\n",
      "units_12: 480\n",
      "units_13: 416\n",
      "units_14: 256\n",
      "units_15: 192\n",
      "units_16: 32\n",
      "units_17: 224\n",
      "units_18: 64\n",
      "units_19: 96\n",
      "Score: 46.13557052612305\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "num_layers: 13\n",
      "units_0: 256\n",
      "units_1: 512\n",
      "learning_rate: 0.01\n",
      "units_2: 480\n",
      "units_3: 192\n",
      "units_4: 384\n",
      "units_5: 160\n",
      "units_6: 448\n",
      "units_7: 416\n",
      "units_8: 32\n",
      "units_9: 384\n",
      "units_10: 416\n",
      "units_11: 416\n",
      "units_12: 64\n",
      "units_13: 384\n",
      "units_14: 320\n",
      "units_15: 352\n",
      "units_16: 352\n",
      "units_17: 480\n",
      "units_18: 512\n",
      "units_19: 128\n",
      "Score: 51.65671412150065\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "num_layers: 15\n",
      "units_0: 384\n",
      "units_1: 512\n",
      "learning_rate: 0.01\n",
      "units_2: 288\n",
      "units_3: 32\n",
      "units_4: 416\n",
      "units_5: 416\n",
      "units_6: 384\n",
      "units_7: 480\n",
      "units_8: 320\n",
      "units_9: 320\n",
      "units_10: 384\n",
      "units_11: 320\n",
      "units_12: 352\n",
      "units_13: 224\n",
      "units_14: 224\n",
      "units_15: 384\n",
      "units_16: 352\n",
      "units_17: 256\n",
      "units_18: 416\n",
      "units_19: 416\n",
      "Score: 52.01379903157552\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 128\n",
      "units_1: 384\n",
      "learning_rate: 0.0001\n",
      "units_2: 160\n",
      "units_3: 288\n",
      "units_4: 128\n",
      "units_5: 224\n",
      "units_6: 448\n",
      "units_7: 512\n",
      "units_8: 128\n",
      "units_9: 512\n",
      "units_10: 288\n",
      "units_11: 224\n",
      "units_12: 480\n",
      "units_13: 64\n",
      "units_14: 96\n",
      "units_15: 192\n",
      "units_16: 224\n",
      "units_17: 384\n",
      "units_18: 480\n",
      "units_19: 448\n",
      "Score: 57.083395640055336\n",
      "\n",
      "Trial 11 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 64\n",
      "units_1: 512\n",
      "learning_rate: 0.0001\n",
      "units_2: 192\n",
      "units_3: 96\n",
      "units_4: 160\n",
      "units_5: 128\n",
      "units_6: 64\n",
      "units_7: 288\n",
      "units_8: 32\n",
      "units_9: 64\n",
      "units_10: 288\n",
      "units_11: 224\n",
      "units_12: 384\n",
      "units_13: 448\n",
      "units_14: 128\n",
      "units_15: 32\n",
      "units_16: 448\n",
      "units_17: 512\n",
      "units_18: 256\n",
      "units_19: 256\n",
      "Score: 61.29922231038412\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "num_layers: 17\n",
      "units_0: 192\n",
      "units_1: 160\n",
      "learning_rate: 0.0001\n",
      "units_2: 416\n",
      "units_3: 96\n",
      "units_4: 448\n",
      "units_5: 64\n",
      "units_6: 352\n",
      "units_7: 192\n",
      "units_8: 320\n",
      "units_9: 32\n",
      "units_10: 160\n",
      "units_11: 448\n",
      "units_12: 96\n",
      "units_13: 416\n",
      "units_14: 288\n",
      "units_15: 416\n",
      "units_16: 128\n",
      "units_17: 192\n",
      "units_18: 224\n",
      "units_19: 192\n",
      "Score: 62.8551991780599\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "num_layers: 20\n",
      "units_0: 256\n",
      "units_1: 416\n",
      "learning_rate: 0.01\n",
      "units_2: 320\n",
      "units_3: 384\n",
      "units_4: 192\n",
      "units_5: 480\n",
      "units_6: 480\n",
      "units_7: 32\n",
      "units_8: 32\n",
      "units_9: 416\n",
      "units_10: 480\n",
      "units_11: 192\n",
      "units_12: 416\n",
      "units_13: 256\n",
      "units_14: 288\n",
      "units_15: 64\n",
      "units_16: 256\n",
      "units_17: 64\n",
      "units_18: 224\n",
      "units_19: 64\n",
      "Score: 63.045125325520836\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "num_layers: 19\n",
      "units_0: 448\n",
      "units_1: 96\n",
      "learning_rate: 0.0001\n",
      "units_2: 448\n",
      "units_3: 480\n",
      "units_4: 128\n",
      "units_5: 320\n",
      "units_6: 352\n",
      "units_7: 128\n",
      "units_8: 320\n",
      "units_9: 320\n",
      "units_10: 288\n",
      "units_11: 128\n",
      "units_12: 256\n",
      "units_13: 96\n",
      "units_14: 384\n",
      "units_15: 256\n",
      "units_16: 32\n",
      "units_17: 32\n",
      "units_18: 32\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_layers: 16\n",
      "units_0: 512\n",
      "units_1: 448\n",
      "learning_rate: 0.001\n",
      "units_2: 32\n",
      "units_3: 32\n",
      "units_4: 32\n",
      "units_5: 32\n",
      "units_6: 32\n",
      "units_7: 32\n",
      "units_8: 32\n",
      "units_9: 32\n",
      "units_10: 32\n",
      "units_11: 32\n",
      "units_12: 32\n",
      "units_13: 32\n",
      "units_14: 32\n",
      "units_15: 32\n",
      "Score: nan\n"
     ]
    }
   ],
   "source": [
    "# shows 10 best trials and their paramters.\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6ea8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can take those paramters of the best trials. and train the model again on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993dd23e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
